## 1.文档中提到了“小陀螺”是赛场上的一种经典战术，请简述它为什么会给传统的自瞄算法带来巨大挑战？

机器人在小陀螺模式下，云台和底盘处于分离状态，在底盘绕运动中心高速自旋的同时云台保持稳定不动。在这种情况下，视觉识别的难度会大大上升，<u>**一是自瞄很难跟上装甲板的高速转动，基本上我方机器人的云台运动会滞后于装甲板的运动；即使使用了前述的预测算法，由于装甲板在很短的时间内就会在车身的一侧“消失“，这往往会导致预测失误，给出的提前量过大使得预测值超出车身范围，从而打空；二是即使跟随到一个装甲板后，那个装甲板随着底盘的转动很快消失在视野中，此时就要锁定另一块装甲板，使得云台在切换目标的过程中会来回转动，无法稳定，导致弹丸命中率下降，且从操作手的第一界面看来，整个画面不断晃动带来晕眩感，给操作带来极大困扰。**</u>炮火轰炸从理论层面上也不可行，因为英雄机器人开火冷却时间长且弹丸价格高昂。



## 2.在使用传统视觉方法识别装甲板时，文档中提到通常需要**降低相机曝光**。请结合你自己的理解，解释为什么低曝光设置对提取亮着的灯条特征更有利？

传统的灯条特征选取的整体流程是恰当的降低曝光，提取二值化后的灯条轮廓，根据几何关系配对灯条，识别出装甲板中间的数字区域，对数字进行模板匹配、SVM 分类或其他 OCR 识别。降低曝光以保证灯条**不会出现过曝而显现白色**但同时又要能够**看清装甲板中间的数字**，以便进行模板匹配、svm分类或其他数字识别。避免灯条区域亮度全部饱和或者边缘模糊，丢失了形状信息，无法提取装甲板的几何特征。总体来说<u>**低曝光的作用就是在“灯条不过曝”和“数字可见”之间找到一个平衡点**</u>。



## 3.文档花了很多篇幅介绍为什么视觉开发推荐使用 **Ubuntu (Linux)** 系统而不是Windows，请总结一下作者给出的至少三个主要理由。

- Ubuntu是一个Debian系分支的第一大系统，是当前<u>**用户量最大的linux发行版**</u>。因此，遇到任何问题一般都能够在用户社区[askubuntu](https://askubuntu.com/)中得到解答。它的安装也非常的方便，并且在更新到20.04后，ubuntu的桌面美观性也有提升。同时，ROS是在Ubuntu之下开发的。如果要使用ROS，Ubuntu是你的不二之选。

- Linux下开发C++程序相比Windows有无与伦比的优势，**<u>可以方便的配置各种第三方库和依赖</u>**。常言道python好用是因为有大量开箱即用的第三方库，可以轻松通过pip安装，而Linux下通过yum/apt/pacman等包安装软件管理的软件包，可视作C/C++隐藏的库安装/管理利器。apt是Debian系发行版用于管理第三方库的一个软件，负责管理系统中安装的各类软件包，开发包，依赖库。可以通过apt轻松地安装各种软件（可执行文件）、开发库（头文件headers，.so动态链接库等。

- Linux的内核和上层系统都比Windows更加精简，故在<u>**运行时占用的各类资源都要小于Windows**</u>。在不打开任何应用的情况下，笔者的电脑在运行Windows10时占用的内存为4.2G，cpu占用率在10-20%左右，而运行Ubuntu20.04LTS的时候，只使用了2.2G的内存，cpu占用率只有10%不到。这样，在运行视觉算法程序时，可以更充分地利用系统资源，最大程度利用电脑的性能。

- Linux对于深度学习的支持比Widnows更加友好，经常有sh脚本<u>**能够一键配置开发环境**</u>。此外Linux对一些设备驱动的支持也更完善，可以选择挂载自己需要的驱动和IO，并且精简属于自己的内核，增加实时性补丁等。

  

## 4.请用你自己的话，简要描述**图像分类 (Image Classification)** 和**目标检测 (Object Detection)** 这两个任务的核心区别是什么？

**图像分类：给定一张图片，通过算法确定这张图像的分类，又叫图像识别。图像识别的输出是整张图片的标记，简要过程为将图片信息转化为向量，然后产生向量空间的映射，整个过程可以函数化表达。该过程类似于监督学习，预先将很多事物标签化，然后根据整幅输入图像的内容，预测该图像所属的类别标签，预测该图像所属的类别标签。

**目标检测**：目标检测不仅要判断图片中是否有对应的物体，还要**<u>输出关于这些物体具体的位置信息</u>**。和目标检测相似的“目标定位”的任务则是对图像中的一个特定物体进行定位，而目标检测算法中，图像内含有的对象种类和数量都是**未知的**。目标检测的输出是目标物体的位置和类别，相对于图像分类复杂度更高，应用场景更广泛。



## 5.文档提到，由于镜头制造工艺等原因，相机会产生“畸变”（Distortion）。请用你自己的话简单描述什么是图像畸变，以及为什么在进行精确测量前，我们需要对相机进行标定（Calibration）？

由于凸透镜**本身的性质**和镜头制造的**工艺**问题，使得光线在通过镜头时无法保持物体在空间中原本的位置关系而发生**畸变**，畸变主要分为切向畸变和桶型畸变，具体表现为图形的位移和线条的弯曲。

然而这些畸变都能够通过数学建模并由反向解算而得到还原。这需要通过**相机标定**来去除这种畸变以便还原图像中物体的真实位置。**<u>通过这些参数对图像进行“校正”，让图像恢复到接近真实世界的几何关系，从而保证数据准确性</u>**。



## 6.请阐述：`solvePnP`函数的主要作用是什么？谈谈自己对于PnP的理解。

 根据输入的信息，包括相机内参、若干个三维空间坐标点以及它们在图像上的对应像素坐标（2D 点），输出旋转向量（rvec）和平移向量（tvec），可以实现机器人的位姿估计，可控制的导航，瞄准与预测。

solvePnP函数解决了很多机器人在现实层面遇到的问题，把摄像头类比为眼睛，那么solvePnP这个核心函数相当于大脑的视觉中枢，利用特定的图像关系（2D-3D)，能将二维的图像准确还原成三维的空间，从而获取外界信息，灵活作出实时的反应。



## 7.请阐述：为什么在进行目标运动预测时，需要使用卡尔曼滤波器这类工具，而不是简单地用两帧之间的位置差来计算速度？它在机器人运动预测任务中主要解决了什么问题？

如果像初中物理一样用两帧之间的位置差来计算速度，那么一定会存在几个严重问题：

1.**数据波动**：传感器测量会不可避免的存在抖动和噪声，而根据这种简单算法，会将很小的误差放大，造成数据的剧烈波动

2.**信息单一**：信息来源单一，利用不充分。如果目标被遮挡或者出现特殊情况，那么这种算法将会完全失效

3.**预测能力差**：由于不能结合先前的运动趋势和预测能力，难以正确决策下一步目标的具体位置



而卡尔曼滤波器在机器人运动预测任务中主要解决了：

1.**噪声对抗**：在噪声观测下，得到相对准确的位置和速度。滤掉测量噪声，得到平滑轨迹。

2.**容错性**：目标短暂丢失时，轨迹不会中断，而是继续推算出合理位置。

3.**提前量计算**：在机器人瞄准、拦截等任务中，需要预测目标在未来的实际位置。KF 能够给出稳定的未来位置估计。



